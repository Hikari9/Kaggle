{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Integer Sequence Learning - Training Data\n",
    "\n",
    "Link: https://www.kaggle.com/c/integer-sequence-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_filename = 'input/train.csv'\n",
    "test_filename = 'input/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect the data\n",
    "import csv\n",
    "\n",
    "train_data_raw = list(csv.reader(open(train_filename)))\n",
    "test_data_raw = list(csv.reader(open(test_filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize training data\n",
    "def gcd(a, b):\n",
    "    return (a if a >= 0 else -a) if b == 0 else gcd(b, a % b)\n",
    "\n",
    "def array_gcd(array):\n",
    "    if not array: return 1\n",
    "    g = array[0]\n",
    "    for x in array:\n",
    "        g = gcd(g, x)\n",
    "    return g\n",
    "\n",
    "def normalize(array):\n",
    "    g = array_gcd(array)\n",
    "    return map(lambda x: x / g, array) if g > 1 else array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform sequence into python lists\n",
    "train_data = map(lambda (id, sequence): [int(id), normalize(map(int, sequence.split(',')))], train_data_raw[1:])\n",
    "test_data = map(lambda (id, sequence): [int(id), map(int, sequence.split(','))], test_data_raw[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743879\n"
     ]
    }
   ],
   "source": [
    "# find out the total length of all sequences\n",
    "print sum(map(lambda data: len(data[1]), train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compress training data\n",
    "import numpy as np\n",
    "\n",
    "nums = set()\n",
    "for id, sequence in train_data:\n",
    "    nums.update(sequence)\n",
    "    \n",
    "decompress_dict = list(nums)\n",
    "compress_dict = {value: index for index, value in enumerate(decompress_dict)}\n",
    "\n",
    "def compress(data):\n",
    "    return compress_dict[data]\n",
    "\n",
    "def decompress(data):\n",
    "    return decompress_dict[data]\n",
    "\n",
    "compressed_train_data = {id: map(compress, sequence) for id, sequence in train_data}\n",
    "compressed_train_var = {id: np.var(sequence) if sequence else 0 for id, sequence in train_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristics\n",
    "\n",
    "1. Exact match\n",
    "    - use hash of compressed array ~O(1)\n",
    "    - array[:-1] == test => array[-1]\n",
    "    - in case of tie, print most likely\n",
    "    - in case of more ties, print any\n",
    "2. Prefix match\n",
    "    - use prefix hashes ~O(1)\n",
    "    - array[:len(test)] == test => array[len(test)]\n",
    "    - in case of tie, print most likely\n",
    "    - in case of more ties, print the one with minimum len(array)\n",
    "    - in case of more ties, print the one with least variance\n",
    "    - in case of more ties, try suffix match\n",
    "4. Suffix match\n",
    "    - use suffix hashes ~O(1)\n",
    "    - array[-len(test)-1:-1] == test => array[-1]\n",
    "    - in case of tie, print most likely\n",
    "    - in case of more ties, print one with minimum len(array)\n",
    "    - in case of more ties, print one with least variance\n",
    "    - in case of more ties, try substring match\n",
    "3. Substring match\n",
    "    - radix search suffix array O(n log n)\n",
    "    - array[a:b] == test => array[b]\n",
    "    - in case of tie, print most likely\n",
    "    - in case of more ties, print the one with the minimum len(array)\n",
    "    - in case of more ties, print the one with leat variance\n",
    "    - in case of more ties, print any\n",
    "4. Unmatched\n",
    "    - Use polynomial extrapolation O(n ^ 3)\n",
    "    - If length is too long, don't bother\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hashing algorithm\n",
    "def hash(array):\n",
    "    h = 0\n",
    "    mask = (1L << 64) - 1\n",
    "    for x in array:\n",
    "        h = (h * 31 + x + 1) & mask\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction function that ranks information according to:\n",
    "# 1) mode of next number\n",
    "# 2) original sequence length\n",
    "# 3) variance of original sequence\n",
    "# returns the best predicted value\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def prediction(indices):\n",
    "    # [(id1, target1), (id2, target2), ...]\n",
    "    # get mode\n",
    "    frequency = defaultdict(int)\n",
    "    for id, target in indices:\n",
    "        frequency[target] += 1\n",
    "    \n",
    "    ctd = compressed_train_data\n",
    "    ctvar = compressed_train_var\n",
    "    # return compressed_train_data[max(indices, key = lambda(id, target): (frequency[target], -len(ctd[id]), -ctvar[id], -id))[0]]\n",
    "    return max(indices, key = lambda(id, target): (frequency[target], -len(ctd[id]), -ctvar[id], -id))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1) exact match heuristic\n",
    "\n",
    "exact_hash = defaultdict(list)\n",
    "for id, data in compressed_train_data.items():\n",
    "    exact_hash[hash(data[:-1])].append((id, data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) prefix match heuristic\n",
    "prefix_hash = defaultdict(list)\n",
    "for id, data in compressed_train_data.items():\n",
    "    # compute prefix hashes, excluding the exact hash\n",
    "    h = 0\n",
    "    mask = (1L << 64) - 1\n",
    "    for x in data[:-1]:\n",
    "        prefix_hash[h].append((id, x))\n",
    "        h = (h * 31 + x + 1) & mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3) suffix match heuristic\n",
    "suffix_hash = defaultdict(list)\n",
    "for id, data in compressed_train_data.items():\n",
    "    # compute suffix hashes, excluding the exact hash\n",
    "    h = 0\n",
    "    mask = (1L << 64) - 1\n",
    "    if len(data) > 1:\n",
    "        for x in data[-2::-1]:\n",
    "            suffix_hash[h].append((id, data[-1]))\n",
    "            h = (h * 31 + x + 1) & mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def hash_match(array, hash_set=exact_match, compressed=False, normalized=True):\n",
    "    \n",
    "    # compress if needed\n",
    "    if not compressed: array = map(compress, array)\n",
    "    if not normalized:\n",
    "        g = array_gcd(array)\n",
    "        array = normalize(array)\n",
    "        \n",
    "    # match using the hash_set\n",
    "    h = hash(array[::-1] if hash_set is suffix_hash else array)\n",
    "    if h not in hash_set: return None\n",
    "    \n",
    "    # return a prediction\n",
    "    ans = prediction(hash_set[h])\n",
    "    ans = ans if compressed else decompress(ans)\n",
    "    return ans if normalized else ans * g\n",
    "\n",
    "# test, expected is 507289\n",
    "print hash_match(\n",
    "    hash_set   = exact_hash,\n",
    "    array      = [1, 24, 300, 2599, 17451, 82703, 303831, 564817, 364166, 211996, 224487, 171243, 383824, 347046, 511217, 24766, 322849, 483304, 199467, 124713, 108798],\n",
    "    compressed = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact:  [1, 1, 2, 3] 14\n",
      "Prefix: [1, 1, 2, 3] 5\n",
      "Suffix: [1, 1, 2, 3] 2\n"
     ]
    }
   ],
   "source": [
    "# test, fibonacci sequence\n",
    "fibonacci = [1, 1, 2, 3]\n",
    "print 'Exact: ', fibonacci, hash_match(fibonacci, exact_hash, compressed=False)\n",
    "print 'Prefix:', fibonacci, hash_match(fibonacci, prefix_hash, compressed=False)\n",
    "print 'Suffix:', fibonacci, hash_match(fibonacci, suffix_hash, compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the values that have no compressed key\n",
    "suffix = defaultdict(int)\n",
    "\n",
    "for id, data in test_data:\n",
    "    last = 0\n",
    "    for x in reversed(data):\n",
    "        if x not in compress_dict:\n",
    "            suffix[last] += 1\n",
    "            break\n",
    "        last += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there's a difference if arrays are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54047 45812 398041 3636\n"
     ]
    }
   ],
   "source": [
    "# sequences with unknown lasts\n",
    "unknown_last = defaultdict(int)\n",
    "unknown_mid = defaultdict(int)\n",
    "unknown_id = set()\n",
    "for id, data in test_data:\n",
    "    if data[-1] not in compress_dict:\n",
    "        unknown_last[data[-1]] += 1\n",
    "        unknown_id.add(id)\n",
    "    for x in data[:-1]:\n",
    "        if x not in compress_dict:\n",
    "            unknown_mid[x] += 1\n",
    "            unknown_id.add(id)\n",
    "print len(unknown_id), len(unknown_last), len(unknown_mid), len(set.intersection(set(unknown_last.keys()), set(unknown_mid.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52981 44898 387061 3357\n"
     ]
    }
   ],
   "source": [
    "# sequences with unknown lasts\n",
    "unknown_last = defaultdict(int)\n",
    "unknown_mid = defaultdict(int)\n",
    "unknown_id = set()\n",
    "for id, data in test_data:\n",
    "    data = normalize(data)\n",
    "    if data[-1] not in compress_dict:\n",
    "        unknown_last[data[-1]] += 1\n",
    "        unknown_id.add(id)\n",
    "    for x in data[:-1]:\n",
    "        if x not in compress_dict:\n",
    "            unknown_mid[x] += 1\n",
    "            unknown_id.add(id)\n",
    "print len(unknown_id), len(unknown_last), len(unknown_mid), len(set.intersection(set(unknown_last.keys()), set(unknown_mid.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
